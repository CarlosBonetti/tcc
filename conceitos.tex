% !TEX root = main.tex

\chapter{Fundamentação teórica e trabalhos relacionados}

Esta revisão de literatura não será exaustiva ao ponto de revisitar os mesmos assuntos abordados no trabalho original de \cite{Silq1} e focará somente nos pontos onde este novo trabalho divergiu. Alguns assuntos fundamentais, entretanto, foram expostos novamente com o intuito de facilitar o processo de entendimento deste TCC como um trabalho independente. É o caso, por exemplo, das seções relacionadas aos Qualis, Lattes e das tecnologias base utilizadas no sistema.

Em um primeiro momento, é apresentada a problemática envolvida no processo de avaliação da produção científica no Brasil e a motivação para a criação do SILQ. Após esta Seção, são introduzidos conceitos relacionados a sistemas de Recuperação de Informação e Feedback de Relevância, tópicos explorados por este trabalho para a tentativa de aumento da exatidão do algoritmo de classificação e avaliação da eficácia do sistema. Por último, são apresentados conceitos e padrões arquiteturais e tecnológicos que foram explorados para o desenvolvimento da segunda versão do SILQ.

\section{Produção e avaliação científicas no Brasil}

A produção científica é uma das atividades universitárias que cumpre uma função básica dentro das instituições e que merece notável destaque. É através dela que o conhecimento produzido na Universidade é difundido à sociedade, externalizando descobertas para outros pesquisadores e para a própria comunidade \cite{Crispim}.

No Brasil, o Ministério de Ciência, Tecnologia e Inovação (MCTI) é o órgão de administração direta que possui, entre sua lista de competências, a política nacional de pesquisa científica, tecnológica e inovação; e o planejamento, coordenação, supervisão e controle das atividades da ciência e tecnologia \cite{MCTI-Institucional}. Uma das agências subordinadas ao MCTI é o CNPq (Conselho Nacional de Desenvolvimento Científico e Tecnológico), órgão que tem como principais atribuições \quotes{fomentar a pesquisa científica e tecnológica e incentivar a formação de pesquisadores brasileiros} \cite{CNPq-Institucional}.

Analisando não só a produção científica, cabe ao Ministério da Educação (MEC), através de sua fundação subordinada, a CAPES (Coordenação de Aperfeiçoamento de Pessoal de Nível Superior) a avaliação dos programas de pós-graduação das universidades Brasileiras \cite{CAPES-Institucional}. Um dos principais critérios de avaliação se dá pela quantidade e qualidade das produções científicas, através de um conjunto de procedimentos denominado Qualis \cite{CAPES-Classificacao}.

\subsection{Qualis}

A classificação da qualidade da produção intelectual é realizada pela CAPES (Coordenação de Aperfeiçoamento de Pessoal de Nível Superior) através de um conjunto de procedimentos denominado Qualis. O Qualis afere a qualidade de artigos e outras produções a partir da análise da qualidade dos veículos de divulgação, ou seja, periódicos científicos. Esta classificação é realizada pelas áreas de avaliação em um processo anual de atualização, sendo os veículos enquadrados em estratos indicativos de qualidade: A1 - o mais elevado; A2; B1; B2; B3; B4; B5; C - com peso zero \cite{CAPES-Classificacao}.

O resultado desta estratificação é uma lista com a classificação dos veículos de publicação utilizados pelos programas de pós-graduação (\textit{journals}, revistas, periódicos etc), separados por área e ano de avaliação (um mesmo veículo tem uma avaliação diferente para cada ano de avaliação e área de conhecimento). Desta forma, a avaliação da qualidade de uma produção de um pesquisador é realizada de forma indireta, atribuindo-se a esta produção o estrato dado àquele veículo onde ela foi publicada.

\begin{citacao}
Note-se que o mesmo periódico, ao ser classificado em duas ou mais áreas distintas, pode receber diferentes avaliações. Isto não constitui inconsistência, mas expressa o valor atribuído, em cada área, à pertinência do conteúdo veiculado. Por isso, não se pretende com esta classificação que é específica para o processo de avaliação de cada área, definir qualidade de periódicos de forma absoluta \cite{CAPES-Classificacao}.
\end{citacao}

Até o ano de 2014, como cita o trabalho de \cite[p. 31]{Silq1}, os dados dos resultados das avaliações Qualis encontravam-se estruturados e disponibilizados em documentos no formado PDF e XLS. Também encontravam-se disponível apenas dados referentes ao triênio de 2010-2012. Em 2015, porém, a CAPES alterou seu modo de operação e passou a realizar avaliações anuais, já disponibilizando os novos dados de 2013 e 2014, junto com os antigos, em formato CSV através do WebQualis\footnote{\url{http://qualis.capes.gov.br/webqualis/}} (Hoje plataforma Sucupira).

A Figura \ref{fig:qualis} mostra um exemplo de dados extraídos da tabela Qualis de 2014, contendo ISSN, título, área de avaliação e estrato atribuído a cada periódico avaliado.

\begin{figure}[!h]
   \centering
   \caption{Exemplo de conjunto de dados do Qualis 2014}
   \label{fig:qualis}
   \includegraphics[width=\textwidth]{figuras/qualis_exemplo.png}
\end{figure}

\subsection{Lattes}

Desde a década de 80 notava-se a necessidade de um formulário padrão para registro dos currículos de pesquisadores brasileiros que possibilitasse a busca e seleção de especialistas bem como a geração de um mapa sobre a distribuição da pesquisa científica no Brasil. Em 1999, o CNPq lançou a Plataforma Lattes\footnote{\url{http://lattes.cnpq.br/}}, um sistema de informação para registro e consulta de currículos acadêmicos, e padronizou o Currículo Lattes como o formulário de currículo a ser utilizado no âmbito do Ministério da Ciência e Tecnologia e CNPq \cite{CNPQ-Historico,CNPQ-Sobre}.

Entre os registros contidos em um currículo Lattes, estão os dados gerais do pesquisador, produção bibliográfica, orientações, citações, formação acadêmica, etc. No módulo Produção Bibliográfica, por exemplo, é possível a inserção de artigos publicados em periódicos indexados pelo ISSN, livros e capítulos, textos em jornais ou revistas, trabalhos publicados em anais de eventos, entre outras formas de produções \cite{CNPQ-Ajuda}.

A Plataforma Lattes, além de apresentar seus currículos através de uma interface web usando HTML, também disponibiliza os dados em formato XML, uma linguagem de marcação semiestruturada legível por humanos e máquinas \cite[p. 34]{Silq1}. Foi este o formato utilizado pelo SILQ para a extração dos dados Lattes de um pesquisador, conforme relatado em \cite{Silq1}.

\section{Sistemas de \textit{IR} e métricas de avaliação}

Recuperação de Informação, ou \textit{Information Retrieval} (IR), é a obtenção de informações relevantes, dados certos critérios de busca, de uma coleção maior de informações. Os maiores exemplos atuais de sistemas de IR são os buscadores web \cite{BaezaYates99}. Áreas tipicamente relacionadas com IR e cujas técnicas e definições muita vezes se intersectam são as de \textit{Data Mining}, Sistemas de Recomendação e \textit{Data-Matching}.

\subsection{\textit{Data-Matching}}

Data matching é o processo de comparação entre informações de diferentes fontes com o objetivo de descobrir se de fato representam o mesmo objeto do mundo real \cite{Dorneles2011}. Neste contexto, é denominada de \textit{query} toda consulta submetida ao sistema de IR e de \textit{documentos} o conjunto de dados sobre o qual ocorrerá a pesquisa e do qual, possivelmente, resultará um subconjunto contendo os resultados para a \textit{query}. Desta forma, o algoritmo de avaliação de currículos do SILQ pode ser classificado como um sistema de IR baseado em \textit{data matching} aproximado, utilizando uma função de similaridade textual entre os dados de publicações informados no currículo Lattes de pesquisadores e os registros Qualis para classificação dos resultados.

Um processo de \textit{data matching} aproximado emprega funções de similaridade (ou de distância) para comparar informações, atribuindo um valor, geralmente pertencente ao intervalo real $[0, 1]$, ao quão parecidos (similares) são os dados comparados. Esse valor é chamado de valor de similaridade, no caso da função calcular o quão parecidos são os objetos, ou valor de dissimilaridade no caso da função calcular o quão diferentes são os objetos. Dois objetos são considerados similares se o valor atribuído pela função de similaridade for maior do que um outro valor pré-estipulado pertencente ao intervalo $[0, 1]$. Esse valor é denominado de \textit{threshold} e deve ser estipulado pelo projetista de acordo com a características do sistema, que incluem a função de similaridade utilizada e a natureza semântica e estrutural dos documentos \cite{Dorneles2011}.

A função de similaridade utilizada pelo algoritmo de avaliação de currículos do SILQ é a \textit{n-gram}, com valor de \textit{n} igual a 3 (sendo chamado, neste caso, de \textit{trigram}) \cite{Silq1}. Um \textit{n-gram} é uma sequência de $n$ caracteres contíguos extraídos de um texto qualquer. Por exemplo, a palavra \quotes{Revista} contém o trigrama \textit{\quotes{Rev}}. O conjunto de todos os trigramas possíveis para este mesmo exemplo é $\{\_\_R,\_Re,Rev,evi,vis,ist,sta,ta\_\}$ (o início e final da palavra são modelados com \quotes{espaços} por certas funções para explicitamente indicar o início e o final da sequência). A função de similaridade \textit{n-grams} recebe como parâmetro duas sequências de caracteres, calcula os conjuntos de n-gramas de ambas e retorna a similaridade dos parâmetros como sendo a fração de elementos em comum dos dois conjuntos \cite{Broder97}.

Desta forma, ao avaliar uma publicação qualquer, o SILQ compara, através da função \textit{trigram}, o nome do veículo onde esta publicação foi submetida com cada um dos registros Qualis presentes na base de dados. Se o valor de similaridade for $0.6$ ou maior\footnote{Este valor é o \textit{threshold} padrão para avaliações, mas pode ser configurado pelo sistema.}, o veículo é considerado como um \textit{matching} positivo. O evento com maior similaridade, caso exista, é considerado e seu estrato Qualis é atribuído à publicação que está sendo avaliada.

Algumas questões relacionadas a este processo são a definição do valor de \textit{threshold} ideal para maximizar a precisão do algoritmo \cite{Dorneles2011} e a própria função de similaridade mais indicada para o conjunto de dados em questão \cite{Silva07}. Para ambas as questões, entretanto, é preciso estipular métricas para a medição de quão preciso é o algoritmo de similaridade, para só então testar diferentes técnicas e variáveis até chegar a uma configuração ideal para o conjunto de dados trabalhados. Duas medidas clássicas de IR que podem ser utilizadas neste caso são a precisão (\textit{precision}) e a revocação (\textit{recall}), além de outras derivadas mais indicadas para sistemas que utilizam \textit{ranking}, conforme descrito na Seção \ref{sec:avaliacao-ir}.

\subsection{Feedback de Relevância}

Feedback de relevância (ou \textit{Relevance Feedback}) é uma característica de alguns sistemas de recuperação de informação que utilizam dados providos pelo usuário para aumentar a exatidão de suas respostas. De maneira particular, o usuário dá \textit{feedback} sobre um conjunto inicial de valores retornados pelo sistema, que então passa a considerar as informações de resultados relevantes ou não relevantes para processar novas \textit{queries} \cite[p. 178]{Manning2008}.

Tradicionalmente, sistemas que utilizam esta técnica dão a possibilidade para o usuário informar palavras-chave, selecionar ou marcar resultados relevantes ou não relevantes ou responder questões sobre seus interesses \cite{Kelly2003}. Pode-se distinguir dois tipos de \textit{feedback} de usuário: explícito e implícito. No primeiro, o usuário interage com o sistema alimentando-o com informações de julgamento (marcando resultados relevantes, selecionando melhores resultados etc); no segundo, o sistema infere que alguns resultados foram melhores que outros por métricas derivadas, como itens selecionados para visualização, tempo de permanência na página ou ações de \textit{scroll} do navegador \cite{White2001}. \textit{Feedback} implícito, de maneira geral, é menos confiável do que explícito por utilizar fontes indiretas de evidência \cite{Manning2008}.

Segundo \cite{Manning2008}, feedback de relevância pode proporcionar ganhos substanciais na performance de sistemas de recuperação de informação, porém a avaliação de sua eficácia em um sistema de IR pode não ser trivial. Um dos métodos para tal mensuração é traçar gráficos de precisão-revocação antes e depois de uma rodada de \textit{feedback} do usuário e comparar os resultados. Esta técnica, porém, é trapaceira pois os documentos julgados pelo usuário com certeza serão melhor ranqueados. Para uma avaliação justa devem ser levados em conta somente documentos que não foram vistos pelo usuário. Um outro método de avaliação requere dois conjuntos, o primeiro utilizado para a \textit{query} inicial e para receber \textit{feedback} do usuário, e o segundo para avaliação via comparação, que contém os resultados desejados previamente estabelecidos por um especialista. A performance do sistema pode ser medido através da comparação dos dois conjuntos, antes e após a inclusão dos dados de \textit{feedback} do usuário.

\subsection{Avaliação de sistemas IR} \label{sec:avaliacao-ir}

Um dos desafios em projetar sistemas de IR está em escolher técnicas que sejam efetivas para a aplicação. Um processo importante no desenvolvimento de tais aplicações, portanto, é o de avaliação, que envolve a medição de certos aspectos do sistema baseados em métricas \cite{Manning2008}.

\subsubsection{Precisão e Revocação}

Em sistemas de reconhecimento de padrões e/ou informações baseados em classificações binárias\footnote{Que só fazem distinção entre dois possíveis resultados para uma busca: ou o elemento é relevante para a \textit{query} em questão ou não é.}, precisão (ou valor preditivo positivo) é a fração dos objetos retornados que são relevantes, enquanto a revocação (ou sensibilidade) é a fração de todos os objetos relevantes que foram retornados \cite{Sammut2001}. Desta forma, \textit{precision} (precisão) e \textit{recall} (revocação) podem ser consideradas medidas de correção e completude e são métricas base para o entendimento da relevância dos resultados retornados \cite{Euzenat07}.

Entretanto, precisão e revocação são medidas baseadas em conjuntos, computadas usando coleções de documentos não ordenados, ou seja, que são retornados sem uma distinção de ordem. São necessárias diferentes medidas para avaliar resultados ordenados \cite{Manning2008}.

\subsubsection{\textit{Precision at $k$ (P@k)} e \textit{R-Precision}}

Para alguns sistemas de IR, em especial aqueles que manipulam grandes volumes de dados, não são relevantes todas as respostas a uma \textit{query}, mas somente os primeiros $k$ resultados. Neste caso, podem ser realizadas mensurações da precisão considerando somente um certo limite de resultados, por exemplo, 10 ou 20 documentos. Este valor é conhecido como \textit{precision at $k$}, por exemplo, \textit{precision at 10}, sendo 10 o número de resultados considerados  \cite{Manning2008}.

Uma das desvantagens desta medida é sua instabilidade em comparação com outras, principalmente de sua média já que o número total de documentos relevantes para uma \textit{query} tem uma forte influência no valor. Um exemplo é uma \textit{query} que só possua 1 item relevante e que ele seja o primeiro resultado retornado, mas ainda  assim o valor de \textit{precision at 10} é $0.1$, já que outros 9 itens não relevantes foram retornados.

Uma alternativa que alivia este problema é chamado de \textit{R-Precision}. Esta medida requer que o conjunto $R$ de todos os documentos relevantes para certa \textit{query} seja conhecido. A partir deste conjunto calcula-se a precisão de uma \textit{query} que retornou $r$ resultados relevantes como sendo $r/|R|$, ou seja, a fração dos itens relevantes que foram de fato retornados. Neste caso, ao analisar os primeiros $|R|$ resultados de uma \textit{query}, por definição, não apenas o valor da precisão é $r/|R|$ como o próprio valor de revocação também é $r/|R|$, ou seja, os valores de precisão e revocação são idênticos ao utilizar tal métrica \cite{Manning2008}.

\subsubsection{Média de Rank Recíproco} \label{sec:mrr}

A média de rank recíproco (\textit{MRR - Mean Reciprocal Rank}), é uma medida estatística utilizada na avaliação de processos que produzem uma lista de resultados a uma \textit{query} ordenados por probabilidade de corretude \cite{Liu2009}.

A média é dada por:

$$
MRR = {1 \over |Q|} \sum_{i=1}^{|Q|} {1 \over rank(i)}
$$

Sendo $Q$ o conjunto de \textit{queries} sobre a qual a média é calculada e $rank(i)$ a posição do primeiro item relevante para a $i$-ésima \textit{query}.

Se um item relevante é o primeiro resultado retornado, então o rank recíproco (RR) é 1. Se o item relevante foi retornado na segunda posição, $RR = 1/2 = 0.5$ e assim por diante. Em outras palavras, MRR é o inverso da posição do primeiro item relevante de uma \textit{query} e uma medida particularmente interessante para sistemas em que somente o primeiro resultado importa \cite{Mcfee2010}, como no SILQ. A métrica não define, porém, o que fazer quando mais de um resultado correto foi retornado. Se nenhum resultado correto foi retornado, entretanto, comumente utiliza-se valor de rank recíproco igual a $0$.

\subsubsection{Conjunto de testes}

A forma padrão de realizar medições em sistemas de IR envolve o uso de um \textit{conjunto de testes}. Este conjunto é uma coleção de exemplos contendo \textit{queries} e seus respectivos resultados corretos, geralmente avaliados por um especialista, e usados apenas para realizar a avaliação do sistema. Em sistemas que dependem de um conjunto de treino para alimentar o algoritmo, como os baseados em \textit{machine learning}, o conjunto de testes não é previamente conhecido pelo sistema \cite{Ripley1995}.

As \textit{queries} do conjunto de testes são submetidas ao sistema e os resultados retornados comparados com aqueles informados pelo especialista, produzindo uma série de medidas que podem ser utilizadas para a avaliação do sistema \cite{Witten2005}.

\section{Arquitetura de sistemas baseados na \textit{Web}}

Nesta Seção são introduzidos conceitos e fundamentos relacionados à construção, interoperabilidade e arquitetura geral de sistemas baseados na Web. A maioria destes conceitos já estão consolidados na indústria de software e são aqui explanados com o objetivo de familiarizar o leitor com os assuntos discutidos no decorrer do desenvolvimento deste trabalho, bem como para apresentar as justificativas tecnológicas que motivaram as alterações arquiteturais realizadas no SILQ.

\subsection{\textit{Web services} e a arquitetura \textit{REST}}

Segundo a W3C (\textit{World Wide Web Consortium}), \textit{web services} são serviços que provém meios de interoperabilidade padronizados entre diferentes aplicações de software rodando em ambientes e/ou plataformas heterogêneas. Um \textit{web service}, portanto, oferece tal serviço de interoperabilidade através da \textit{World Wide Web}, expondo uma interface descrita em um formato legível por máquinas. Diferentes entidades consomem tal serviço através de trocas de mensagem utilizando o formato especificado \cite{W3C-Web-Services}.

\textit{Representational state transfer} (REST) é um estilo arquitetural utilizado para a implementação de um \textit{web service}, baseado no protocolo HTTP \cite{Fielding02}. Serviços web que implementam uma API no estilo REST também são chamadas de \textit{RESTful APIs} e comumente utilizam JSON como formato de intercomunicação, podendo utilizar também XML, Atom, texto, entre outros \cite{richardson2013restful}.

Um exemplo de comunicação entre um servidor web rodando um serviço de consulta de uma biblioteca e um cliente (outra aplicação) que desejasse saber a coleção de livros de seu acervo seria o seguinte:

\begin{enumerate}
\item O cliente envia um requisição HTTP do tipo GET para a URI \url{http://api.biblioteca.exemplo.com/acervo};

\item O servidor da biblioteca responde ao pedido com a coleção de livros de seu acervo em formato JSON. Um exemplo de resposta poderia ser:

\begin{lstlisting}[language=json, caption=Exemplo de uma resposta JSON dada por um serviço RESTful]
{
  acervo: [
    {
      titulo: "Uma breve história do tempo",
      autor: "Stephen W. Hawking"
    },
    {
      titulo: "Metodologia de Pesquisa para Ciência da Computação",
      autor: "Raul Sidnei Wazlawick"
    },
    ...
  ]
}
\end{lstlisting}

\item A resposta em JSON é recebida pelo cliente, interpretada e o conteúdo processado (consumido) da maneira que a aplicação necessitar.

\end{enumerate}

Desta forma, clientes que necessitem da informação de acervo da biblioteca do exemplo acima não precisam se preocupar com os detalhes tecnológicos necessários para realizar essa consulta (se os dados estão em um banco de dados local ou distribuído, relacional ou não, qual linguagem é utilizada para consulta, etc), eles apenas fazem uma requisição HTTP de um certo tipo e em uma URI pré-estipulada (normalmente definidas na documentação do \textit{web service}) e são servidos com a informação desejada.

Uma interpretação moderna de tal arquitetura é denominada \textit{microsserviço}, que compartilha das características de um \textit{web service} clássico, mas cuja maior diferença seria que os \textit{microservices} tem como objetivo prover um serviço específico, desempenhando uma única função minimalista, porém completa \cite{Fowler-microservices}. Deste ponto de vista, um \textit{web service} clássico monolítico\footnote{Dentro do conceito da arquitetura de microsserviços, monolítica é uma aplicação construída como uma unidade única e indivisível, em oposição ao conceito composto e distribuído dos microsserviços \cite{Fowler-microservices}.} poderia, na maior parte das vezes, ser decomposto em vários microsserviços, cada um especializado em uma função e podendo ter características tecnológicas completamente distintas.

Outra definição comumente utilizada em aplicações que implementam a arquitetura REST (ou mesmo outras arquiteturas web) é a divisão da aplicação em dois níveis lógicos, o \textit{server-side} e o \textit{client-side}. Dentro do modelo cliente-servidor, o \textit{server-side} de uma aplicação é toda infraestrutura de um servidor que recebe e processa requisições, geralmente retornando uma resposta à este pedido. O \textit{client-side}, por sua vez, é toda infraestrutura que efetua a requisição ao servidor, recebe sua resposta e a manipula para apresentar o resultado ao usuário. No contexto das aplicações web modernas, \textit{server}/\textit{client-side} são geralmente associados aos termos \textit{back-end} e \textit{front-end} da aplicação, respectivamente, apesar de não possuírem significados completamente idênticos \cite{Jia2005}.

Tais conceitos estimularam a criação de uma API REST para o SILQ, com o objetivo de tornar disponível, de forma programática, os dados Qualis inseridos em sua base de dados e o serviço de avaliação de currículos. Desta forma, outras aplicações podem consumir os serviços oferecidos pelo sistema sem se preocupar com os detalhes tecnológicos utilizados pelo SILQ para implementar tais funcionalidades, aumentando a facilidade de integração com outros sistemas.

\subsection{Teste automatizado de software}

O processo de desenvolvimento de software é uma atividade em que comumente ocorrem, apesar dos esforços e do emprego de técnicas e ferramentas, diversos erros (\textit{bugs}) no produto final. A Garantia da Qualidade de Software é uma disciplina que agrega as atividades que ocorrem de forma paralela ao desenvolvimento com o objetivo de minimizar a ocorrência de erros e riscos no produto \cite{Barbosa2000}.

Três das técnicas utilizadas para a garantia da qualidade de teste são a Verificação, Validação e Teste \cite{Barbosa2000}. A verificação avalia se o produto está sendo desenvolvido corretamente, enquanto a validação avalia se o produto correto está sendo desenvolvido \cite{Boehm1981}. Já o teste, no contexto de software, geralmente implica na execução do próprio produto, considerando-se valores de entrada pertinentes para teste, para verificação de certas funcionalidades do sistema \cite{Barbosa2000}.

Segundo \cite{Pressman2001} e \cite[cap. 5]{SWEBOK2014}, diferentes tipos de testes podem ser agrupados em níveis de acordo com o grau de especificidade do módulo ou do requerimento sendo testado. Testes unitários têm como objetivo verificar o funcionamento de unidades indivisíveis e isoladas de um software, garantindo que cada uma delas funcione conforme especificado. Testes de integração, por sua vez, tem por objetivo encontrar falhas na integração entre as unidades de um sistema. Testes de sistema, ou testes \textit{end-to-end} (fim a fim), executam a validação do sistema final como um todo, simulando as ações que um usuário real realizaria ao utilizar a aplicação.
